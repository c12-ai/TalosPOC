{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649d5982",
   "metadata": {},
   "source": [
    "### Release notes\n",
    "\n",
    "In this version we changed PROMPT changed to:\n",
    "\n",
    "```\n",
    "你是一名准入判别代理,负责判断用户输入是否在系统定义的领域与可执行范围内\n",
    "\n",
    "# 系统领域范围:\n",
    "你属于实验室智能机器人, 你的名字是Talos, 这个系统是面向小分子合成及 DMPK 实验室的对话式助手,具备机器人任务布置、化学专业问答与实验室运营查询三类核心可执行。\n",
    "机器人可执行/支持: TLC 点板、过柱、LC-MS 前处理与送样、旋蒸、称重入库,以及贯穿纯化流程;另支持 DMPK 稳定性测试。\n",
    "专业问答: TLC 条件设计、过柱条件推荐、旋蒸条件推荐、物质属性查询。\n",
    "运营查询: 实验任务进度、机器人状态、仪器状态、物料位置与状态。\n",
    "\n",
    "# 判断依据\n",
    "1. 领域为小分子合成和 DMPK 场景, 任何超出该范围, 或没有明确表明意图的输入, 视为越界和超越范围。\n",
    "2. 可执行为机器人任务布置、化学专业问答与实验室运营查询三类核心可执行。\n",
    "3. 任何超出该范围, 或没有明确表明意图的输入, 视为越界和超越范围。\n",
    "\n",
    "# 输出格式\n",
    "请严格按照以下 JSON 格式输出结果:\n",
    "{\n",
    "    \"within_domain\": bool,  // 用户输入是否在系统定义的领域范围内\n",
    "    \"within_capacity\": bool, // 用户输入是否在系统定义的可执行范围内\n",
    "    \"feedback\": str         // 对判别结果的简要说明\n",
    "}\n",
    "\n",
    "# 示例\n",
    "示例 1:\n",
    "用户输入: \"请帮我设计一个 TLC 条件\"\n",
    "输出: {\n",
    "    \"within_domain\": true,\n",
    "    \"within_capacity\": true,\n",
    "    \"feedback\": \"用户输入在小分子合成领域内, 且符合系统能力范围.\"\n",
    "}\n",
    "\n",
    "示例 2:\n",
    "用户输入: \"你能告诉我今天的天气吗?\"\n",
    "输出: {\n",
    "    \"within_domain\": false,\n",
    "    \"within_capacity\": false,\n",
    "    \"feedback\": \"用户输入不在小分子合成和 DMPK 领域内, 超出系统能力范围.\"\n",
    "}\n",
    "\n",
    "示例 3:\n",
    "用户输入: \"帮我做一下萃取\"\n",
    "输出: {\n",
    "    \"within_domain\": true,\n",
    "    \"within_capacity\": false,\n",
    "    \"feedback\": \"用户输入在小分子合成领域内, 但不在系统可执行范围内.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22b588",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Prepare dataset\n",
    "\n",
    "Under following cells, we will read data under `data` folder and convert them into pandas dataframe. `senario` property will be used as df name while `examples` will be converted into rows.\n",
    "\n",
    "fetch them from `dfs['<property>']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")  # import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path(\"/Users/drakezhou/Development/big-poc/src/data\")\n",
    "\n",
    "dfs = {}\n",
    "for json_path in data_dir.glob(\"*.json\"):\n",
    "    with json_path.open(encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    senario_name = obj[\"senario\"]\n",
    "\n",
    "    cdf = pd.DataFrame(obj[\"examples\"])\n",
    "\n",
    "    match senario_name:\n",
    "        case \"valid_can_do\":\n",
    "            cdf[\"target_within_domain\"] = True\n",
    "            cdf[\"target_within_capacity\"] = True\n",
    "        case \"valid_cannot_do\":\n",
    "            cdf[\"target_within_domain\"] = True\n",
    "            cdf[\"target_within_capacity\"] = False\n",
    "        case \"invalid\":\n",
    "            cdf[\"target_within_domain\"] = False\n",
    "            cdf[\"target_within_capacity\"] = False\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown senario: {senario_name}\")\n",
    "\n",
    "    dfs[senario_name] = cdf\n",
    "\n",
    "# Example\n",
    "dfs[\"valid_can_do\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e28697",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "Use to evaluate the performance of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db911ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING\n",
    "\n",
    "from langchain_core.messages import AIMessage, AnyMessage, HumanMessage\n",
    "\n",
    "from src.functions.admittance import WatchDogAgent\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from src.classes.operation import OperationResponse\n",
    "    from src.classes.system_state import UserAdmittance\n",
    "\n",
    "watch_dog = WatchDogAgent()\n",
    "\n",
    "\n",
    "def run_watch_dog_agent(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    within_domain_list: list[bool] = []\n",
    "    within_capacity_list: list[bool] = []\n",
    "    feedback_list: list[str] = []\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        input_msg = []\n",
    "        for msg in row[\"dialogue\"]:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                input_msg.append(AIMessage(content=msg[\"message\"]))\n",
    "            elif msg[\"role\"] == \"user\":\n",
    "                input_msg.append(HumanMessage(content=msg[\"message\"]))\n",
    "\n",
    "        res: OperationResponse[list[AnyMessage], UserAdmittance] = watch_dog.run(\n",
    "            user_input=input_msg,\n",
    "            stream_mode=False,\n",
    "        )\n",
    "        within_domain_list.append(res.output.within_domain)\n",
    "        within_capacity_list.append(res.output.within_capacity)\n",
    "        feedback_list.append(res.output.feedback)\n",
    "\n",
    "    dataset = dataset.copy()\n",
    "    dataset[\"within_domain\"] = within_domain_list\n",
    "    dataset[\"within_capacity\"] = within_capacity_list\n",
    "    dataset[\"feedback\"] = feedback_list\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea4f22",
   "metadata": {},
   "source": [
    "Valid Can Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa057d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance using `Valid Can DO` Dataset\n",
    "\n",
    "eval_df = run_watch_dog_agent(dfs[\"valid_can_do\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054367d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add configuration information and show\n",
    "version_control = {\n",
    "    \"model\": \"gpt-5.1\",\n",
    "    \"prompt_version\": \"v1\",\n",
    "}\n",
    "\n",
    "eval_df[\"version_control\"] = [version_control] * len(dfs[\"valid_can_do\"])\n",
    "\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37344f",
   "metadata": {},
   "source": [
    "valid_cannot_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b558eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_valid_cannot_do = run_watch_dog_agent(dfs[\"valid_cannot_do\"])\n",
    "\n",
    "version_control = {\n",
    "    \"model\": \"gpt-5.1\",\n",
    "    \"prompt_version\": \"v1\",\n",
    "}\n",
    "\n",
    "eval_valid_cannot_do[\"version_control\"] = [version_control] * len(dfs[\"valid_cannot_do\"])\n",
    "\n",
    "eval_valid_cannot_do.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656c2ac",
   "metadata": {},
   "source": [
    "Invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f85bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_invalid = run_watch_dog_agent(dfs[\"invalid\"])\n",
    "\n",
    "version_control = {\n",
    "    \"model\": \"gpt-5.1\",\n",
    "    \"prompt_version\": \"v1\",\n",
    "}\n",
    "\n",
    "eval_invalid[\"version_control\"] = [version_control] * len(dfs[\"invalid\"])\n",
    "\n",
    "eval_invalid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67aa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # pyright: ignore[reportMissingImports]\n",
    "import seaborn as sns  # pyright: ignore[reportMissingImports]\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Aggregate evaluation across all datasets and plot confusion matrices\n",
    "combined_eval = pd.concat(\n",
    "    [\n",
    "        eval_df.assign(senario=\"valid_can_do\"),\n",
    "        eval_valid_cannot_do.assign(senario=\"valid_cannot_do\"),\n",
    "        eval_invalid.assign(senario=\"invalid\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_binary_metrics(df: pd.DataFrame, target_col: str, pred_col: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    y_true = df[target_col]\n",
    "    y_pred = df[pred_col]\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[True, False])\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=pd.Index([\"actual_true\", \"actual_false\"]),\n",
    "        columns=pd.Index([\"pred_true\", \"pred_false\"]),\n",
    "    )\n",
    "    return pd.DataFrame(report).T, cm_df\n",
    "\n",
    "\n",
    "domain_report, domain_cm = compute_binary_metrics(\n",
    "    combined_eval,\n",
    "    target_col=\"target_within_domain\",\n",
    "    pred_col=\"within_domain\",\n",
    ")\n",
    "capacity_report, capacity_cm = compute_binary_metrics(\n",
    "    combined_eval,\n",
    "    target_col=\"target_within_capacity\",\n",
    "    pred_col=\"within_capacity\",\n",
    ")\n",
    "\n",
    "display(domain_report)\n",
    "display(capacity_report)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.heatmap(\n",
    "    domain_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Within Domain Confusion Matrix\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(\n",
    "    capacity_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Greens\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Within Capacity Confusion Matrix\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
